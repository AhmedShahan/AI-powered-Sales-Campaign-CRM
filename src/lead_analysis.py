"""
Simple AI Lead Analyzer
‡¶∂‡ßÅ‡¶ß‡ßÅ 3‡¶ü‡¶æ ‡¶ï‡¶æ‡¶ú: Score + Missing Data Fill + Buyer Persona
"""

import os
import pandas as pd
import asyncio
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
import json
from dotenv import load_dotenv
load_dotenv()
# Setup Gemini

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.9
)

print("Gemini ready!")


# Prompt template
prompt = ChatPromptTemplate.from_template("""
You are a B2B sales analyst. Analyze this lead carefully and fill missing information.

Lead Data:
- Name: {name}
- Company: {company}
- Industry: {industry}
- Job Title: {job_title}
- Company Size: {company_size}
- Location: {location}
- Notes: {notes}
- Last Contact: {last_contact}

Return JSON with exactly these fields:
{{
  "priority_score": <number 0-100>,
  "buyer_persona": "<persona type>",
  "filled_industry": "<predict if missing, based on company name>",
  "filled_job_title": "<predict if missing, based on available info>",
  "filled_company_size": "<predict if missing>",
  "filled_notes": "<if notes empty, predict what they need>"
}}

PRIORITY SCORING RULES (0-100):
Consider these factors carefully:

1. ENGAGEMENT SIGNALS (30 points max):
   - Notes with positive signals ("interested", "requested demo", "budget approved") ‚Üí +20-30 points
   - Notes with concerns ("limited budget", "needs follow-up") ‚Üí +5-10 points
   - Empty/no notes ‚Üí 0 points

2. RECENCY OF CONTACT (25 points max):
   - Contacted within last 7 days ‚Üí +25 points
   - Contacted within last 30 days ‚Üí +15 points
   - Contacted 1-3 months ago ‚Üí +10 points
   - Contacted 3+ months ago ‚Üí +5 points
   - Never contacted ‚Üí 0 points (but can still be high priority based on other factors)

3. JOB TITLE SENIORITY (25 points max):
   - C-Level (CEO, CTO, CFO, COO) ‚Üí +25 points
   - VP/Director level ‚Üí +20 points
   - Manager level ‚Üí +15 points
   - Specialist/Analyst ‚Üí +10 points

4. COMPANY SIZE (20 points max):
   - 500+ employees ‚Üí +20 points
   - 200-500 employees ‚Üí +15 points
   - 100-200 employees ‚Üí +12 points
   - 50-100 employees ‚Üí +10 points
   - 10-50 employees ‚Üí +7 points
   - 1-10 employees ‚Üí +5 points

Example scoring:
- Hot lead: CEO + contacted yesterday + "very interested" in notes = 80+ points
- Warm lead: Manager + contacted 2 weeks ago + no strong signals = 50-60 points
- Cold lead: Junior role + never contacted + no notes = 20-30 points

FILLING MISSING DATA:
- Industry: Analyze company name (e.g., "TechBangla" ‚Üí Software, "HealthCare BD" ‚Üí Healthcare)
- Job Title: Use context clues (if unknown, predict based on seniority signals)
- Company Size: Estimate from industry standards and company name
- Notes: Predict likely interests based on industry + role

BUYER PERSONA:
Create descriptive personas like:
- "Enterprise Technology Decision Maker"
- "Growth-Stage Startup Founder"
- "Mid-Market Operations Leader"
- "SMB Business Owner"
""")


async def analyze_lead(row):
    # Handle empty values - treat empty strings as missing
    industry = row.get('industry', '') or 'Not provided'
    job_title = row.get('job_title', '') or 'Not provided'
    company_size = row.get('company_size', '') or 'Not provided'
    notes = row.get('notes', '') or 'Not provided'
    last_contact = row.get('last_contact', '') or 'Never contacted'
    
    try:
        # Call AI
        messages = prompt.format_messages(
            name=row['name'],
            company=row['company'],
            industry=industry,
            job_title=job_title,
            company_size=company_size,
            location=row['location'],
            notes=notes,
            last_contact=last_contact
        )
        
        response = await llm.ainvoke(messages)
        
        # Parse JSON
        result = json.loads(response.content.strip().replace('```json', '').replace('```', ''))
        
        return result
        
    except Exception as e:
        print(f"Error: {e}")
        return {
            'priority_score': 50,
            'buyer_persona': 'Unknown',
            'filled_industry': industry if industry != 'Not provided' else 'Unknown',
            'filled_job_title': job_title if job_title != 'Not provided' else 'Unknown',
            'filled_company_size': company_size if company_size != 'Not provided' else 'Unknown',
            'filled_notes': notes if notes != 'Not provided' else 'N/A'
        }


# Main process
async def process_leads_async(csv_file='sales_leads.csv'):
    """CSV process ‡¶ï‡¶∞‡¶æ - async version"""
    
    # Load CSV
    df = pd.read_csv(csv_file, dtype={'company_size': str})
    print(f"\nLoaded {len(df)} leads\n")
    
    # Add new columns
    df['priority_score'] = 0
    df['buyer_persona'] = ''
    df['ai_filled_industry'] = ''
    df['ai_filled_job_title'] = ''
    df['ai_filled_company_size'] = ''
    df['ai_filled_notes'] = ''
    
    # Process all leads in parallel with real-time output
    print(f"ü§ñ Analyzing {len(df)} leads in parallel...\n")
    
    # Create tasks with indices
    tasks = {}
    for idx, row in df.iterrows():
        task = asyncio.create_task(analyze_lead(row))
        tasks[task] = (idx, row)
    
    # Process results as they complete
    completed_count = 0
    results_dict = {}
    
    for task in asyncio.as_completed(tasks.keys()):
        idx, row = tasks[task]
        try:
            result = await task
            completed_count += 1
            
            # Print output immediately
            print(f"ü§ñ [{completed_count}/{len(df)}] Analyzed: {row['name']}...")
            print(f"   Score: {result['priority_score']}/100 | {result['buyer_persona']}\n")
            
            # Store result with original index
            results_dict[idx] = result
            
        except Exception as e:
            print(f"‚ùå Error analyzing {row['name']}: {e}\n")
            results_dict[idx] = {
                'priority_score': 50,
                'buyer_persona': 'Unknown',
                'filled_industry': row.get('industry', 'Unknown'),
                'filled_job_title': row.get('job_title', 'Unknown'),
                'filled_company_size': row.get('company_size', 'Unknown'),
                'filled_notes': 'Error occurred'
            }
    
    # Update dataframe with results
    for idx, result in results_dict.items():
        row = df.loc[idx]
        df.at[idx, 'priority_score'] = result['priority_score']
        df.at[idx, 'buyer_persona'] = result['buyer_persona']
        
        # Fill missing data - use AI prediction only if original is empty
        df.at[idx, 'ai_filled_industry'] = result.get('filled_industry', row.get('industry', ''))
        df.at[idx, 'ai_filled_job_title'] = result.get('filled_job_title', row.get('job_title', ''))
        df.at[idx, 'ai_filled_company_size'] = result.get('filled_company_size', row.get('company_size', ''))
        df.at[idx, 'ai_filled_notes'] = result['filled_notes']
    
    # Sort by priority score (highest first)
    df = df.sort_values('priority_score', ascending=False)
    
    # Save
    output_file = '/home/shahanahmed/AI-powered-Sales-Campaign-CRM/output/analyzed_leads.csv'
    df.to_csv(output_file, index=False)
    
    print(f"‚úÖ Done! Saved to: {output_file}")
    print(f"‚úÖ Sorted by priority (highest to lowest)\n")
    
    return df


def process_leads(csv_file='sales_leads.csv'):
    """CSV process ‡¶ï‡¶∞‡¶æ - sync wrapper for backward compatibility"""
    return asyncio.run(process_leads_async(csv_file))


# Run
if __name__ == "__main__":
    asyncio.run(process_leads_async('/home/shahanahmed/AI-powered-Sales-Campaign-CRM/dataset/leads.csv'))